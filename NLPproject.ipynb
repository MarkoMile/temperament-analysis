{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 14170,
          "status": "ok",
          "timestamp": 1660489158953,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "vw4zrN3dhVxh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-07 11:19:05.334648: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-09-07 11:19:05.334672: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-09-07 11:19:06.868642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2022-09-07 11:19:06.868662: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-09-07 11:19:06.868687: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marko-pc): /proc/driver/nvidia/version does not exist\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import tldextract\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "STOP_WORDS = nlp.Defaults.stop_words\n",
        "\n",
        "nRowsRead = None  # specify 'None' if want to read whole file\n",
        "postStrings = []\n",
        "typeStrings = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 409,
          "status": "ok",
          "timestamp": 1660489731537,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "YmgbW9Ax3QmE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./input/mbti_1.csv', delimiter=',', nrows=nRowsRead)\n",
        "df.dataframeName = 'mbti_1.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1660489735283,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "me0evtXa3ScU"
      },
      "outputs": [],
      "source": [
        "# making array of array of posts\n",
        "for person,type in zip(df['posts'],df['type']):\n",
        "    postStrings.append([type,person.split('|||')])\n",
        "\n",
        "# removing excess single parentheses\n",
        "\n",
        "for i in range(0,len(postStrings)):\n",
        "    postStrings[i][1][0] = postStrings[i][1][0][1:]\n",
        "    postStrings[i][1][-1] = postStrings[i][1][-1][:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>[http://www.youtube.com/watch?v=qsXHcwe3krw, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>[I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>[Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>[Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>[You're fired., That's another silly misconcep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  [http://www.youtube.com/watch?v=qsXHcwe3krw, h...\n",
              "1  ENTP  [I'm finding the lack of me in these posts ver...\n",
              "2  INTP  [Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  [Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  [You're fired., That's another silly misconcep..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#splitting posts into list of posts\n",
        "df['posts'] = df['posts'].apply(lambda x: x.split('|||'))\n",
        "\n",
        "# removing excess single parentheses\n",
        "def removeParentheses(posts):\n",
        "    posts[0] = posts[0][1:]\n",
        "    posts[-1] = posts[-1][:-1]\n",
        "    return posts\n",
        "df['posts'] = df['posts'].apply(lambda x: removeParentheses(x))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[http://www.youtube.com/watch?v=qsXHcwe3krw, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[You're fired., That's another silly misconcep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0     2  [http://www.youtube.com/watch?v=qsXHcwe3krw, h...\n",
              "1     3  [I'm finding the lack of me in these posts ver...\n",
              "2     3  [Good one  _____   https://www.youtube.com/wat...\n",
              "3     3  [Dear INTP,   I enjoyed our conversation the o...\n",
              "4     3  [You're fired., That's another silly misconcep..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#label encoding type\n",
        "\n",
        "def labelEncodeType(type):\n",
        "  if type == 'ISTJ' or type == 'ISFJ' or type == 'ESTJ' or type == 'ESFJ':\n",
        "    type = 0 #GUARDIAN\n",
        "  elif type == 'ISTP' or type == 'ISFP' or type == 'ESTP' or type == 'ESFP':\n",
        "    type = 1 #ARTISAN\n",
        "  elif type == 'INFJ' or type == 'INFP' or type == 'ENFP' or type == 'ENFJ':\n",
        "    type = 2  # IDEALIST\n",
        "  elif type == 'INTJ' or type == 'INTP' or type == 'ENTP' or type == 'ENTJ':\n",
        "    type = 3  # RATIONALIST\n",
        "  return type\n",
        "\n",
        "df['type'] = df['type'].apply(lambda x: labelEncodeType(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    4167\n",
              "3    3311\n",
              "1     745\n",
              "0     452\n",
              "Name: type, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "URL_REGEX = r\"\"\"(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))\"\"\"\n",
        "DOMAIN_REGEX = \"^(?:https?:\\/\\/)?(?:[^@\\/\\n]+@)?(?:www\\.)?([^:\\/?\\n]+)\"\n",
        "COMMENT_REGEX = r\"\\[.*?\\]\"\n",
        "ELLIPSIS_REGEX = r\"^(\\ *\\.{3}\\ *)|(\\ *\\.{3}\\ *)$\"\n",
        "\n",
        "def urlReplace(stringToReplace):\n",
        "\tdomain = tldextract.extract(stringToReplace.group())\n",
        "\treturn domain.domain + '.' + domain.suffix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CONSIDER TRYING WITHOUT STOPWORD REMOVAL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[enfp intj moments youtubecom sportscenter pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[Im finding lack posts alarming, Sex boring it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Good  youtubecom, Of course I I know thats bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[Dear INTP I enjoyed conversation day Esoteric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[Youre fired, Thats silly misconception That a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0     2  [enfp intj moments youtubecom sportscenter pla...\n",
              "1     3  [Im finding lack posts alarming, Sex boring it...\n",
              "2     3  [Good  youtubecom, Of course I I know thats bl...\n",
              "3     3  [Dear INTP I enjoyed conversation day Esoteric...\n",
              "4     3  [Youre fired, Thats silly misconception That a..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def containsOnlyUrlsOrNumbers(post):\n",
        "\tsplits = post.split()\n",
        "\tfor str in splits:\n",
        "\t\tif(not re.search(URL_REGEX,str) and not re.search('^\\d+$',str) and not re.search('^\\.\\.\\.+$',str)):\n",
        "\t\t\treturn 1\n",
        "\treturn 0\n",
        "\n",
        "def containsComments(post):\n",
        "\tsplits = post.split('] ')\n",
        "\tfor str in splits:\n",
        "\t\tif(not re.search(COMMENT_REGEX,str)):\n",
        "\t\t\treturn 1\n",
        "\t\treturn 0\n",
        "\n",
        "def removeEllipsis(post):\n",
        "\treturn re.sub(ELLIPSIS_REGEX,'',post)\n",
        "\n",
        "def removeWhitespace(post):\n",
        "\tpost = \" \".join(post.split())\n",
        "\treturn post\n",
        "\n",
        "def removeStopWords(post):\n",
        "\tpost = \" \".join([t for t in post.split() if t not in STOP_WORDS])\n",
        "\treturn post\n",
        "\n",
        "def removeSpecialChars(post): #ALSO REMOVES PUNCTUATION\n",
        "\tpost = re.sub('[^A-Z a-z 0-9-]+','',post)\n",
        "\treturn post\n",
        "\n",
        "def removeAccentedChars(post):\n",
        "\tpost = unicodedata.normalize('NFKD',post).encode('ascii','ignore').decode('utf-8','ignore')\n",
        "\treturn post\n",
        "\n",
        "def formatPerson(person):\n",
        "\tperson = list(map(lambda x: removeWhitespace(x), person))\n",
        "\tperson = [post for post in person if (\n",
        "\t\tcontainsOnlyUrlsOrNumbers(post) and containsComments(post))]\n",
        "\tperson = list(map(lambda x: removeEllipsis(x), person))\n",
        "\tperson = list(map(lambda x: re.sub(URL_REGEX, urlReplace, x), person))\n",
        "\tperson = list(map(lambda x: removeStopWords(x),person))\n",
        "\tperson = list(map(lambda x: removeSpecialChars(x), person))\n",
        "\tperson = list(map(lambda x: removeAccentedChars(x), person))\n",
        "\treturn person\n",
        "\n",
        "df['posts']= df['posts'].apply(lambda x:formatPerson(x))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "executionInfo": {
          "elapsed": 1934,
          "status": "ok",
          "timestamp": 1660490778787,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "4lDomPao3UXN"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[enfp intj moments youtubecom sportscenter pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[I m find lack post alarm, sex bore its positi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[good   youtubecom, of course I I know that s ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[dear INTP I enjoy conversation day Esoteric g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[you re fire, that s silly misconception that ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0     2  [enfp intj moments youtubecom sportscenter pla...\n",
              "1     3  [I m find lack post alarm, sex bore its positi...\n",
              "2     3  [good   youtubecom, of course I I know that s ...\n",
              "3     3  [dear INTP I enjoy conversation day Esoteric g...\n",
              "4     3  [you re fire, that s silly misconception that ..."
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#do the nlp tokenization with spaCy\n",
        "\n",
        "def convertToLemmas(posts):\n",
        "  docs = nlp.pipe(posts, n_process=-1, disable=[\"tok2vec\", \"parser\"])\n",
        "  lemmaList = []\n",
        "  postList = []\n",
        "  for doc in docs:\n",
        "    for token in doc:\n",
        "      lemma = str(token.lemma_)\n",
        "      if lemma == '-PRON-' or lemma == 'be':\n",
        "        lemma = token.text\n",
        "      lemmaList.append(lemma)\n",
        "    postList.append(\" \".join(lemmaList))\n",
        "    lemmaList= []\n",
        "  return postList\n",
        "\n",
        "#for the dataframe:\n",
        "df['posts']= df['posts'].apply(lambda x:convertToLemmas(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(path_or_buf=\"./csv_files/df.csv\")\n",
        "# df = pd.read_csv(filepath_or_buffer=\"./csv_files/df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>enfp intj moments youtubecom sportscenter play...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>What life-changing experience life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>youtubecom youtubecom On repeat today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>May PerC Experience immerse you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>The thing INFJ friend posted facebook committi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>2</td>\n",
              "      <td>I going close facebook months back wanting abl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>2</td>\n",
              "      <td>30 Seconds Mars - All collections It fitting m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>2</td>\n",
              "      <td>I seen it agree I actually think time I watche...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>2</td>\n",
              "      <td>Ok watched Underworld 4 Awakening good film Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>2</td>\n",
              "      <td>I want turn emotions I hide world I need me</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>408949 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                              posts\n",
              "0        2  enfp intj moments youtubecom sportscenter play...\n",
              "0        2                 What life-changing experience life\n",
              "0        2              youtubecom youtubecom On repeat today\n",
              "0        2                    May PerC Experience immerse you\n",
              "0        2  The thing INFJ friend posted facebook committi...\n",
              "...    ...                                                ...\n",
              "8674     2  I going close facebook months back wanting abl...\n",
              "8674     2  30 Seconds Mars - All collections It fitting m...\n",
              "8674     2  I seen it agree I actually think time I watche...\n",
              "8674     2  Ok watched Underworld 4 Awakening good film Co...\n",
              "8674     2        I want turn emotions I hide world I need me\n",
              "\n",
              "[408949 rows x 2 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#SPLITTING POSTS INTO SEPERATE ROWS\n",
        "df = df.explode('posts')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    197249\n",
              "3    155773\n",
              "1     34619\n",
              "0     21308\n",
              "Name: type, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#common words removal\n",
        "freq_comm = pd.Series(' '.join(df['posts'].tolist()).split()).value_counts()\n",
        "f20= freq_comm[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df['posts'] = df['posts'].apply(lambda x: ' '.join([t for t in x.split() if t not in f20]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#rare words removal\n",
        "rare= freq_comm[freq_comm.values==1]\n",
        "# rare= freq_comm[freq_comm.values<3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['posts'] = df['posts'].apply(lambda x: ' '.join([t for t in x.split() if t not in rare]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1705</th>\n",
              "      <td>0</td>\n",
              "      <td>Im quiet person its nature There times topic b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>0</td>\n",
              "      <td>I sense makes sense</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6014</th>\n",
              "      <td>0</td>\n",
              "      <td>Would travel If so where And long Yes Either d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7938</th>\n",
              "      <td>0</td>\n",
              "      <td>ESTP In MBTI its ok pick I E I think Se domina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6742</th>\n",
              "      <td>0</td>\n",
              "      <td>The - The American Midland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4847</th>\n",
              "      <td>3</td>\n",
              "      <td>Same Objects bodies homework friendsyou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1671</th>\n",
              "      <td>3</td>\n",
              "      <td>This actually difficult question Social life l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5447</th>\n",
              "      <td>3</td>\n",
              "      <td>Ok I wont pretend I know this How exactly INTP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>3</td>\n",
              "      <td>fall love male enfp fall love female entp inst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5783</th>\n",
              "      <td>3</td>\n",
              "      <td>Interesting topic What drives me If exception ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                              posts\n",
              "1705     0  Im quiet person its nature There times topic b...\n",
              "630      0                                I sense makes sense\n",
              "6014     0  Would travel If so where And long Yes Either d...\n",
              "7938     0  ESTP In MBTI its ok pick I E I think Se domina...\n",
              "6742     0                         The - The American Midland\n",
              "...    ...                                                ...\n",
              "4847     3            Same Objects bodies homework friendsyou\n",
              "1671     3  This actually difficult question Social life l...\n",
              "5447     3  Ok I wont pretend I know this How exactly INTP...\n",
              "677      3  fall love male enfp fall love female entp inst...\n",
              "5783     3  Interesting topic What drives me If exception ...\n",
              "\n",
              "[40000 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df0 = df[df['type'] == 0].sample(10000)\n",
        "df1 = df[df['type'] == 1].sample(10000)\n",
        "df2 = df[df['type'] == 2].sample(10000)\n",
        "df3 = df[df['type'] == 3].sample(10000)\n",
        "\n",
        "dfr = pd.concat([df0,df1,df2,df3],)\n",
        "dfr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = dfr['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv = CountVectorizer(dtype='b')\n",
        "text_counts = cv.fit_transform(dfr['posts'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40000, 27807)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_counts.toarray().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfr_bow = pd.DataFrame(text_counts.toarray(),columns=cv.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>001</th>\n",
              "      <th>002</th>\n",
              "      <th>005</th>\n",
              "      <th>006</th>\n",
              "      <th>00s</th>\n",
              "      <th>018</th>\n",
              "      <th>0200</th>\n",
              "      <th>038</th>\n",
              "      <th>...</th>\n",
              "      <th>zoquaro</th>\n",
              "      <th>zosio913</th>\n",
              "      <th>zster</th>\n",
              "      <th>zubz</th>\n",
              "      <th>zuchinni</th>\n",
              "      <th>zuckerberg</th>\n",
              "      <th>zuko</th>\n",
              "      <th>zynthaxx</th>\n",
              "      <th>zyzz</th>\n",
              "      <th>zz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 27807 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   00  000  001  002  005  006  00s  018  0200  038  ...  zoquaro  zosio913  \\\n",
              "0   0    0    0    0    0    0    0    0     0    0  ...        0         0   \n",
              "1   0    0    0    0    0    0    0    0     0    0  ...        0         0   \n",
              "\n",
              "   zster  zubz  zuchinni  zuckerberg  zuko  zynthaxx  zyzz  zz  \n",
              "0      0     0         0           0     0         0     0   0  \n",
              "1      0     0         0           0     0         0     0   0  \n",
              "\n",
              "[2 rows x 27807 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfr_bow.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dfr_bow.to_csv(path_or_buf=\"./csv_files/dfr_bow.csv\")\n",
        "# dfr.to_csv(path_or_buf=\"./csv_files/dfr.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML ALGORITHMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(random_state=42,n_estimators=500,n_jobs=-1,max_depth=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.35875\n",
            "CPU times: user 8min 54s, sys: 1min 23s, total: 10min 18s\n",
            "Wall time: 2min 32s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "def classify(X,y):\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  X=scaler.fit_transform(X)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2,random_state=42,stratify=y)\n",
        "\n",
        "  rfc.fit(X_train,y_train)\n",
        "  y_pred = rfc.predict(X_test)\n",
        "  ac = accuracy_score(y_test,y_pred)\n",
        "  print(\"accuracy: \",ac)\n",
        "\n",
        "\n",
        "classify(dfr_bow,y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPipjDsvaeWPmm+I2AKTUv7",
      "collapsed_sections": [],
      "mount_file_id": "1_TEjG8vJVKTW0yXQp99YYob3Mif_LgsQ",
      "name": "NLPproject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
