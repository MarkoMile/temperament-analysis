{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 14170,
          "status": "ok",
          "timestamp": 1660489158953,
          "user": {
            "displayName": "Marko MilenkoviÄ‡",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "vw4zrN3dhVxh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import tldextract\n",
        "# import tensorflow as tf\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nRowsRead = None  # specify 'None' if want to read whole file\n",
        "postStrings = []\n",
        "typeStrings = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df.to_csv(path_or_buf=\"./csv_files/df_spojeni.csv\")\n",
        "# df = pd.read_csv(filepath_or_buffer=\"./csv_files/df_spojeni.csv\")\n",
        "# df=df.drop([3559])\n",
        "\n",
        "df = pd.read_pickle(\"../neuralNet/pickle_files/df_odvojeni_word_vectors.pkl\")\n",
        "df = df.groupby(['type', 'avgWordLen'], sort=False,as_index=False).agg({'posts':' '.join,'upperCount':'first','stopWordCount':'first','urlCount':'first','wordCount':'first','avgWordLen':'first','vectors':lambda x:np.array(x)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df0 = df[df['type'] == 0].sample(450)\n",
        "df1 = df[df['type'] == 1].sample(450)\n",
        "df2 = df[df['type'] == 2].sample(450)\n",
        "df3 = df[df['type'] == 3].sample(450)\n",
        "\n",
        "dfr = pd.concat([df0,df1,df2,df3],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = dfr['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv = CountVectorizer(dtype=np.uint8)\n",
        "text_counts = cv.fit_transform(dfr['posts'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfr_bow = pd.DataFrame(text_counts.toarray(),columns=cv.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfr_bow.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Num. of words: \" + str(len(list(dfr_bow.columns))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfr_features = dfr.drop(labels=['posts','type','vectors'],axis=1).reset_index(drop=True)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML ALGORITHMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfc = []\n",
        "rfc.append(RandomForestClassifier(random_state=42,n_estimators=100,n_jobs=-1))\n",
        "rfc.append(RandomForestClassifier(random_state=42,n_estimators=200,n_jobs=-1))\n",
        "rfc.append(RandomForestClassifier(random_state=42,n_estimators=500,n_jobs=-1))\n",
        "rfc.append(RandomForestClassifier(random_state=42,n_estimators=1000,n_jobs=-1))\n",
        "rfc.append(RandomForestClassifier(random_state=42,n_estimators=2000,n_jobs=-1))\n",
        "rfc.append(RandomForestClassifier(random_state=42,n_estimators=10000,n_jobs=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.53      0.56        90\n",
            "           1       0.57      0.61      0.59        90\n",
            "           2       0.53      0.53      0.53        90\n",
            "           3       0.59      0.61      0.60        90\n",
            "\n",
            "    accuracy                           0.57       360\n",
            "   macro avg       0.57      0.57      0.57       360\n",
            "weighted avg       0.57      0.57      0.57       360\n",
            "\n",
            "##################################################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.54      0.59        90\n",
            "           1       0.58      0.66      0.61        90\n",
            "           2       0.61      0.56      0.58        90\n",
            "           3       0.60      0.68      0.64        90\n",
            "\n",
            "    accuracy                           0.61       360\n",
            "   macro avg       0.61      0.61      0.61       360\n",
            "weighted avg       0.61      0.61      0.61       360\n",
            "\n",
            "##################################################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.61      0.67        90\n",
            "           1       0.62      0.68      0.65        90\n",
            "           2       0.64      0.59      0.61        90\n",
            "           3       0.62      0.72      0.67        90\n",
            "\n",
            "    accuracy                           0.65       360\n",
            "   macro avg       0.66      0.65      0.65       360\n",
            "weighted avg       0.66      0.65      0.65       360\n",
            "\n",
            "##################################################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.60      0.69        90\n",
            "           1       0.64      0.73      0.68        90\n",
            "           2       0.66      0.67      0.66        90\n",
            "           3       0.62      0.69      0.65        90\n",
            "\n",
            "    accuracy                           0.67       360\n",
            "   macro avg       0.68      0.67      0.67       360\n",
            "weighted avg       0.68      0.67      0.67       360\n",
            "\n",
            "##################################################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.63      0.72        90\n",
            "           1       0.63      0.74      0.68        90\n",
            "           2       0.69      0.69      0.69        90\n",
            "           3       0.67      0.71      0.69        90\n",
            "\n",
            "    accuracy                           0.69       360\n",
            "   macro avg       0.71      0.69      0.70       360\n",
            "weighted avg       0.71      0.69      0.70       360\n",
            "\n",
            "##################################################\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.63      0.71        90\n",
            "           1       0.63      0.73      0.68        90\n",
            "           2       0.69      0.69      0.69        90\n",
            "           3       0.66      0.70      0.68        90\n",
            "\n",
            "    accuracy                           0.69       360\n",
            "   macro avg       0.70      0.69      0.69       360\n",
            "weighted avg       0.70      0.69      0.69       360\n",
            "\n",
            "##################################################\n",
            "CPU times: user 27min 32s, sys: 6.62 s, total: 27min 39s\n",
            "Wall time: 2min 39s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "X = dfr_features.join(dfr_bow)\n",
        "\n",
        "def classify(X,y,classifier):\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  X=scaler.fit_transform(X)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2,random_state=69,stratify=y)\n",
        "\n",
        "  classifier.fit(X_train,y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  ac = accuracy_score(y_test,y_pred)\n",
        "\n",
        "  # print(\"accuracy: \", ac)\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print(\"##################################################\")\n",
        "\n",
        "for classifier in rfc:\n",
        "  classify(X,y,classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### average accuracy on 100 forests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def classify(X,y):\n",
        "#   scaler = MinMaxScaler(feature_range=(0,1))\n",
        "#   X=scaler.fit_transform(X)\n",
        "\n",
        "#   X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2,random_state=42,stratify=y)\n",
        "\n",
        "#   rfc.fit(X_train,y_train)\n",
        "#   y_pred = rfc.predict(X_test)\n",
        "#   ac = accuracy_score(y_test,y_pred)\n",
        "\n",
        "#   return ac\n",
        "\n",
        "# test = []\n",
        "\n",
        "# for i in range(0,100):\n",
        "#   df0 = df[df['type'] == 0].sample(450)\n",
        "#   df1 = df[df['type'] == 1].sample(450)\n",
        "#   df2 = df[df['type'] == 2].sample(450)\n",
        "#   df3 = df[df['type'] == 3].sample(450)\n",
        "#   dfr = pd.concat([df0, df1, df2, df3],)\n",
        "#   y = dfr['type']\n",
        "#   cv = CountVectorizer(dtype='b')\n",
        "#   text_counts = cv.fit_transform(dfr['posts'])\n",
        "#   dfr_bow = pd.DataFrame(text_counts.toarray(),columns=cv.get_feature_names_out())\n",
        "#   dfr_features = dfr.drop(labels=['posts','type','vectors'],axis=1).reset_index(drop=True)  \n",
        "\n",
        "#   test.append(classify(dfr_features.join(dfr_bow), y))\n",
        "\n",
        "# print(sum(test)/len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import statistics\n",
        "# print(\"max= \"+str(max(test)))\n",
        "# print(\"min= \"+str(min(test)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPipjDsvaeWPmm+I2AKTUv7",
      "collapsed_sections": [],
      "mount_file_id": "1_TEjG8vJVKTW0yXQp99YYob3Mif_LgsQ",
      "name": "NLPproject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
