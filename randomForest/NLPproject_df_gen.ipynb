{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "executionInfo": {
          "elapsed": 14170,
          "status": "ok",
          "timestamp": 1660489158953,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "vw4zrN3dhVxh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import tldextract\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "STOP_WORDS = nlp.Defaults.stop_words\n",
        "\n",
        "nRowsRead = None  # specify 'None' if want to read whole file\n",
        "postStrings = []\n",
        "typeStrings = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "executionInfo": {
          "elapsed": 409,
          "status": "ok",
          "timestamp": 1660489731537,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "YmgbW9Ax3QmE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./input/mbti_1.csv', delimiter=',', nrows=nRowsRead)\n",
        "df.dataframeName = 'mbti_1.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1660489735283,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "me0evtXa3ScU"
      },
      "outputs": [],
      "source": [
        "# making array of array of posts\n",
        "for person,type in zip(df['posts'],df['type']):\n",
        "    postStrings.append([type,person.split('|||')])\n",
        "\n",
        "# removing excess single parentheses\n",
        "\n",
        "for i in range(0,len(postStrings)):\n",
        "    postStrings[i][1][0] = postStrings[i][1][0][1:]\n",
        "    postStrings[i][1][-1] = postStrings[i][1][-1][:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>[http://www.youtube.com/watch?v=qsXHcwe3krw, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>[I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>[Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>[Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>[You're fired., That's another silly misconcep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  [http://www.youtube.com/watch?v=qsXHcwe3krw, h...\n",
              "1  ENTP  [I'm finding the lack of me in these posts ver...\n",
              "2  INTP  [Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  [Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  [You're fired., That's another silly misconcep..."
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#splitting posts into list of posts\n",
        "df['posts'] = df['posts'].apply(lambda x: x.split('|||'))\n",
        "\n",
        "# removing excess single parentheses\n",
        "def removeParentheses(posts):\n",
        "    posts[0] = posts[0][1:]\n",
        "    posts[-1] = posts[-1][:-1]\n",
        "    return posts\n",
        "df['posts'] = df['posts'].apply(lambda x: removeParentheses(x))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[http://www.youtube.com/watch?v=qsXHcwe3krw, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[You're fired., That's another silly misconcep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0     2  [http://www.youtube.com/watch?v=qsXHcwe3krw, h...\n",
              "1     3  [I'm finding the lack of me in these posts ver...\n",
              "2     3  [Good one  _____   https://www.youtube.com/wat...\n",
              "3     3  [Dear INTP,   I enjoyed our conversation the o...\n",
              "4     3  [You're fired., That's another silly misconcep..."
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#label encoding type\n",
        "\n",
        "def labelEncodeType(type):\n",
        "  if type == 'ISTJ' or type == 'ISFJ' or type == 'ESTJ' or type == 'ESFJ':\n",
        "    type = 0 #GUARDIAN\n",
        "  elif type == 'ISTP' or type == 'ISFP' or type == 'ESTP' or type == 'ESFP':\n",
        "    type = 1 #ARTISAN\n",
        "  elif type == 'INFJ' or type == 'INFP' or type == 'ENFP' or type == 'ENFJ':\n",
        "    type = 2  # IDEALIST\n",
        "  elif type == 'INTJ' or type == 'INTP' or type == 'ENTP' or type == 'ENTJ':\n",
        "    type = 3  # RATIONALIST\n",
        "  return type\n",
        "\n",
        "df['type'] = df['type'].apply(lambda x: labelEncodeType(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    4167\n",
              "3    3311\n",
              "1     745\n",
              "0     452\n",
              "Name: type, dtype: int64"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['type'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**PREPROCESSING PIPELINE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "URL_REGEX = r\"\"\"(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))\"\"\"\n",
        "DOMAIN_REGEX = \"^(?:https?:\\/\\/)?(?:[^@\\/\\n]+@)?(?:www\\.)?([^:\\/?\\n]+)\"\n",
        "COMMENT_REGEX = r\"\\[.*?\\]\"\n",
        "ELLIPSIS_REGEX = r\"^(\\ *\\.{3}\\ *)|(\\ *\\.{3}\\ *)$\"\n",
        "\n",
        "def urlReplace(stringToReplace):\n",
        "\tdomain = tldextract.extract(stringToReplace.group())\n",
        "\treturn domain.domain + '.' + domain.suffix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[enfp and intj moments youtube.com sportscente...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Good one _____ https://www.youtube.com/watch?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[Dear INTP, I enjoyed our conversation the oth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[You're fired., That's another silly misconcep...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0     2  [enfp and intj moments youtube.com sportscente...\n",
              "1     3  [I'm finding the lack of me in these posts ver...\n",
              "2     3  [Good one _____ https://www.youtube.com/watch?...\n",
              "3     3  [Dear INTP, I enjoyed our conversation the oth...\n",
              "4     3  [You're fired., That's another silly misconcep..."
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def containsOnlyUrlsOrNumbers(post):\n",
        "\tsplits = post.split()\n",
        "\tfor str in splits:\n",
        "\t\tif(not re.search(URL_REGEX,str) and not re.search('^\\d+$',str) and not re.search('^\\.\\.\\.+$',str)):\n",
        "\t\t\treturn 1\n",
        "\treturn 0\n",
        "\n",
        "def containsComments(post):\n",
        "\tsplits = post.split('] ')\n",
        "\tfor str in splits:\n",
        "\t\tif(not re.search(COMMENT_REGEX,str)):\n",
        "\t\t\treturn 1\n",
        "\t\treturn 0\n",
        "\n",
        "def removeEllipsis(post):\n",
        "\treturn re.sub(ELLIPSIS_REGEX,'',post)\n",
        "\n",
        "def removeWhitespace(post):\n",
        "\tpost = \" \".join(post.split())\n",
        "\treturn post\n",
        "\n",
        "def removeAccentedChars(post):\n",
        "\tpost = unicodedata.normalize('NFKD',post).encode('ascii','ignore').decode('utf-8','ignore')\n",
        "\treturn post\n",
        "\n",
        "def formatPerson(person):\n",
        "\tperson = list(map(lambda x: removeWhitespace(x), person))\n",
        "\tperson = [post for post in person if (containsOnlyUrlsOrNumbers(post) and containsComments(post))]\n",
        "\tperson = list(map(lambda x: removeEllipsis(x), person))\n",
        "\tperson = list(map(lambda x: removeAccentedChars(x), person))\n",
        "\treturn person\n",
        "\n",
        "df['posts']= df['posts'].apply(lambda x:formatPerson(x))\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ADDITIONAL FEATURES AND FINAL FORMATTING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>upperCount</th>\n",
              "      <th>stopWordCount</th>\n",
              "      <th>urlCount</th>\n",
              "      <th>wordCount</th>\n",
              "      <th>avgWordLen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[enfp intj moments youtubecom sportscenter pla...</td>\n",
              "      <td>17</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>585</td>\n",
              "      <td>4.935312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[im finding lack posts alarming, sex boring po...</td>\n",
              "      <td>91</td>\n",
              "      <td>525</td>\n",
              "      <td>4</td>\n",
              "      <td>1214</td>\n",
              "      <td>4.356184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[good youtubecom, of course i i know thats ble...</td>\n",
              "      <td>37</td>\n",
              "      <td>354</td>\n",
              "      <td>3</td>\n",
              "      <td>873</td>\n",
              "      <td>4.789478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[dear intp i enjoyed conversation day esoteric...</td>\n",
              "      <td>69</td>\n",
              "      <td>490</td>\n",
              "      <td>2</td>\n",
              "      <td>1108</td>\n",
              "      <td>4.481933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[youre fired, thats silly misconception that a...</td>\n",
              "      <td>51</td>\n",
              "      <td>447</td>\n",
              "      <td>3</td>\n",
              "      <td>1013</td>\n",
              "      <td>4.512231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts  upperCount  \\\n",
              "0     2  [enfp intj moments youtubecom sportscenter pla...          17   \n",
              "1     3  [im finding lack posts alarming, sex boring po...          91   \n",
              "2     3  [good youtubecom, of course i i know thats ble...          37   \n",
              "3     3  [dear intp i enjoyed conversation day esoteric...          69   \n",
              "4     3  [youre fired, thats silly misconception that a...          51   \n",
              "\n",
              "   stopWordCount  urlCount  wordCount  avgWordLen  \n",
              "0            255         8        585    4.935312  \n",
              "1            525         4       1214    4.356184  \n",
              "2            354         3        873    4.789478  \n",
              "3            490         2       1108    4.481933  \n",
              "4            447         3       1013    4.512231  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def toLower(post):\n",
        "\tpost = post.lower()\n",
        "\treturn post\n",
        "\n",
        "def countUpper(post):\n",
        "  upperCount = sum(map(str.isupper, post.split()))\n",
        "  return upperCount\n",
        "\n",
        "def countWords(post):\n",
        "  count = len(post.split())\n",
        "  return count\n",
        "\n",
        "def avgWordLen(post):\n",
        "  words = post.split()\n",
        "  wordLen = 0\n",
        "  for word in words:\n",
        "    wordLen = wordLen + len(word)\n",
        "  if len(words)>0:\n",
        "    return wordLen/len(words)\n",
        "  else: \n",
        "    return 0\n",
        "\n",
        "def countUrls(post):\n",
        "  return len(re.findall(URL_REGEX,post))\n",
        "\n",
        "def removeStopWords(post):\n",
        "\tpost = \" \".join([t for t in post.split() if t not in STOP_WORDS])\n",
        "\treturn post\n",
        "\n",
        "def removeSpecialChars(post): #ALSO REMOVES PUNCTUATION\n",
        "\tpost = re.sub('[^A-Z a-z 0-9-]+','',post)\n",
        "\treturn post\n",
        "\n",
        "def removeAlphaNumeric(post):\n",
        "  alphaNumRegex = r\"\\b([A-z]+[0-9]+[A-z0-9]*|[0-9]+[A-z]+[A-z0-9]*)\\b\"\n",
        "  post = re.sub(alphaNumRegex, '', post)\n",
        "  return post\n",
        "\n",
        "\n",
        "def removeNumbers(post):\n",
        "  numberRegex = r\"[0-9]+\"\n",
        "  floatRegex = r\"([1-9][0-9]*[eE][1-9][0-9]*|(([1-9][0-9]*\\.)|(\\.[0-9]+))([0-9]*)?([eE][\\-\\+]?[1-9][0-9]*)?)\"\n",
        "  post = re.sub(floatRegex, '', post)\n",
        "  post = re.sub(numberRegex, '', post)\n",
        "  return post\n",
        "\n",
        "def shortenRepeatingChars(post):\n",
        "  repeatingCharRegex = r\"(.)\\1{3,}\" #finds character groups of more than 3 consecutive chars\n",
        "  post = re.sub(repeatingCharRegex,r\"\\1\\1\\1\",post)\n",
        "  return post\n",
        "\n",
        "def removeSingleChars(post): #removes free single chars EXCEPT I or i\n",
        "  singleCharRegex = r\"(^| )[^Ii](( )[^Ii])*( |$)\"\n",
        "  post = re.sub(singleCharRegex,'',post)\n",
        "  return post\n",
        "  \n",
        "\n",
        "df['upperCount'] = df['posts'].apply(lambda x:sum(map(lambda y:countUpper(str(y)),x)))  #COUNT UPPERCASE WORDS\n",
        "df['stopWordCount'] = df['posts'].apply(lambda x:sum(map(lambda y: len([t for t in y.split() if t in STOP_WORDS]),x)))  #COUNT STOPWORDS\n",
        "df['urlCount'] = df['posts'].apply(lambda x:sum(map(lambda y:countUrls(str(y)),x)))   #COUNT URLS\n",
        "\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y: re.sub(URL_REGEX, urlReplace, y), x))) #remove urls\n",
        "\n",
        "df['wordCount'] = df['posts'].apply(lambda x:sum(map(lambda y:countWords(str(y)),x)))         #COUNT WORDS\n",
        "df['avgWordLen'] = df['posts'].apply(lambda x:sum(map(lambda y:avgWordLen(str(y)),x))/len(x)) #AVERAGE WORD LEN\n",
        "\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y: removeSpecialChars(str(y)), x))) #remove special chars (including punctuation)\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y:removeStopWords(str(y)),x))) #remove stopwords\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y: removeAlphaNumeric(str(y)), x)))  #remove alphanumeric words\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y: removeNumbers(str(y)), x))) #remove numbers (int and float)\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y:toLower(str(y)),x))) #lowercase all\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y: shortenRepeatingChars(str(y)), x))) #shorten all character repeats to 3 characters\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y: removeSingleChars(str(y)), x))) #remove all single character words except I and i\n",
        "df['posts'] = df['posts'].apply(lambda x:list(map(lambda y: removeWhitespace(str(y)), x))) #remove excess whitespaces again to clean up\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "executionInfo": {
          "elapsed": 1934,
          "status": "ok",
          "timestamp": 1660490778787,
          "user": {
            "displayName": "Marko Milenković",
            "userId": "00943616786887211077"
          },
          "user_tz": -120
        },
        "id": "4lDomPao3UXN"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>upperCount</th>\n",
              "      <th>stopWordCount</th>\n",
              "      <th>urlCount</th>\n",
              "      <th>wordCount</th>\n",
              "      <th>avgWordLen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>[enfp intj moment youtubecom sportscenter play...</td>\n",
              "      <td>17</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>585</td>\n",
              "      <td>4.935312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[I m find lack post alarming, sex boring posit...</td>\n",
              "      <td>91</td>\n",
              "      <td>525</td>\n",
              "      <td>4</td>\n",
              "      <td>1214</td>\n",
              "      <td>4.356184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[good youtubecom, of course I I know that s bl...</td>\n",
              "      <td>37</td>\n",
              "      <td>354</td>\n",
              "      <td>3</td>\n",
              "      <td>873</td>\n",
              "      <td>4.789478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[dear intp I enjoy conversation day esoteric g...</td>\n",
              "      <td>69</td>\n",
              "      <td>490</td>\n",
              "      <td>2</td>\n",
              "      <td>1108</td>\n",
              "      <td>4.481933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[you re fire, that s silly misconception that ...</td>\n",
              "      <td>51</td>\n",
              "      <td>447</td>\n",
              "      <td>3</td>\n",
              "      <td>1013</td>\n",
              "      <td>4.512231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts  upperCount  \\\n",
              "0     2  [enfp intj moment youtubecom sportscenter play...          17   \n",
              "1     3  [I m find lack post alarming, sex boring posit...          91   \n",
              "2     3  [good youtubecom, of course I I know that s bl...          37   \n",
              "3     3  [dear intp I enjoy conversation day esoteric g...          69   \n",
              "4     3  [you re fire, that s silly misconception that ...          51   \n",
              "\n",
              "   stopWordCount  urlCount  wordCount  avgWordLen  \n",
              "0            255         8        585    4.935312  \n",
              "1            525         4       1214    4.356184  \n",
              "2            354         3        873    4.789478  \n",
              "3            490         2       1108    4.481933  \n",
              "4            447         3       1013    4.512231  "
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#do the nlp tokenization with spaCy\n",
        "\n",
        "def convertToLemmas(posts):\n",
        "  docs = nlp.pipe(posts, n_process=-1)\n",
        "  lemmaList = []\n",
        "  postList = []\n",
        "  for doc in docs:\n",
        "    for token in doc:\n",
        "      lemma = str(token.lemma_)\n",
        "      if lemma == '-PRON-' or lemma == 'be':\n",
        "        lemma = token.text\n",
        "      lemmaList.append(lemma)\n",
        "    postList.append(\" \".join(lemmaList))\n",
        "    lemmaList= []\n",
        "  return postList\n",
        "  # return \" \".join(postList)\n",
        "\n",
        "#for the dataframe:\n",
        "df['posts']= df['posts'].apply(lambda x:convertToLemmas(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.explode(\"posts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_pickle(\"./pickle_files/df_odvojeni.pkl\")\n",
        "# df.to_pickle(\"./pickle_files/df_spojeni.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    197249\n",
              "3    155773\n",
              "1     34619\n",
              "0     21308\n",
              "Name: type, dtype: int64"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['type'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**common words removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "I    583690\n",
              "dtype: int64"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freq_comm = pd.Series(' '.join(df['posts'].tolist()).split()).value_counts()\n",
        "f20= freq_comm[:1]\n",
        "f20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['posts'] = df['posts'].apply(lambda x: ' '.join([t for t in x.split() if t not in f20]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**rare words removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "yourselfbe              1\n",
              "outbe                   1\n",
              "leviintj                1\n",
              "sensinginstantly        1\n",
              "ymiristp                1\n",
              "                       ..\n",
              "spiritus                1\n",
              "therandomsciencegirl    1\n",
              "etcpresent              1\n",
              "disagreeingi            1\n",
              "marsall                 1\n",
              "Length: 107343, dtype: int64"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rare= freq_comm[freq_comm.values==1]\n",
        "rare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['posts'] = df['posts'].apply(lambda x: ' '.join([t for t in x.split() if t not in rare]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_pickle(\"./pickle_files/df_odvojeni_wordsRemoved.pkl\")\n",
        "# df.to_pickle(\"./pickle_files/df_spojeni_wordsRemoved.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       enfp intj moment youtubecom play youtubecom prank\n",
              "0                      what life - change experience life\n",
              "0                   youtubecom youtubecom on repeat today\n",
              "0                             may perc experience immerse\n",
              "0       the thing infj friend post facebook commit sui...\n",
              "                              ...                        \n",
              "8674    go close facebook month want able message fami...\n",
              "8674              second collection it fitting mood right\n",
              "8674    see agree actually think time watch movie begi...\n",
              "8674    ok watch underworld awakening good film compar...\n",
              "8674                    want turn emotion hide world need\n",
              "Name: posts, Length: 408949, dtype: object"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['posts']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>upperCount</th>\n",
              "      <th>stopWordCount</th>\n",
              "      <th>urlCount</th>\n",
              "      <th>wordCount</th>\n",
              "      <th>avgWordLen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>enfp intj moment youtubecom play youtubecom prank</td>\n",
              "      <td>17</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>585</td>\n",
              "      <td>4.935312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>what life - change experience life</td>\n",
              "      <td>17</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>585</td>\n",
              "      <td>4.935312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>youtubecom youtubecom on repeat today</td>\n",
              "      <td>17</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>585</td>\n",
              "      <td>4.935312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>may perc experience immerse</td>\n",
              "      <td>17</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>585</td>\n",
              "      <td>4.935312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>the thing infj friend post facebook commit sui...</td>\n",
              "      <td>17</td>\n",
              "      <td>255</td>\n",
              "      <td>8</td>\n",
              "      <td>585</td>\n",
              "      <td>4.935312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408944</th>\n",
              "      <td>2</td>\n",
              "      <td>go close facebook month want able message fami...</td>\n",
              "      <td>104</td>\n",
              "      <td>659</td>\n",
              "      <td>2</td>\n",
              "      <td>1409</td>\n",
              "      <td>4.137663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408945</th>\n",
              "      <td>2</td>\n",
              "      <td>second collection it fitting mood right</td>\n",
              "      <td>104</td>\n",
              "      <td>659</td>\n",
              "      <td>2</td>\n",
              "      <td>1409</td>\n",
              "      <td>4.137663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408946</th>\n",
              "      <td>2</td>\n",
              "      <td>see agree actually think time watch movie begi...</td>\n",
              "      <td>104</td>\n",
              "      <td>659</td>\n",
              "      <td>2</td>\n",
              "      <td>1409</td>\n",
              "      <td>4.137663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408947</th>\n",
              "      <td>2</td>\n",
              "      <td>ok watch underworld awakening good film compar...</td>\n",
              "      <td>104</td>\n",
              "      <td>659</td>\n",
              "      <td>2</td>\n",
              "      <td>1409</td>\n",
              "      <td>4.137663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408948</th>\n",
              "      <td>2</td>\n",
              "      <td>want turn emotion hide world need</td>\n",
              "      <td>104</td>\n",
              "      <td>659</td>\n",
              "      <td>2</td>\n",
              "      <td>1409</td>\n",
              "      <td>4.137663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>408949 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        type                                              posts  upperCount  \\\n",
              "0          2  enfp intj moment youtubecom play youtubecom prank          17   \n",
              "1          2                 what life - change experience life          17   \n",
              "2          2              youtubecom youtubecom on repeat today          17   \n",
              "3          2                        may perc experience immerse          17   \n",
              "4          2  the thing infj friend post facebook commit sui...          17   \n",
              "...      ...                                                ...         ...   \n",
              "408944     2  go close facebook month want able message fami...         104   \n",
              "408945     2            second collection it fitting mood right         104   \n",
              "408946     2  see agree actually think time watch movie begi...         104   \n",
              "408947     2  ok watch underworld awakening good film compar...         104   \n",
              "408948     2                  want turn emotion hide world need         104   \n",
              "\n",
              "        stopWordCount  urlCount  wordCount  avgWordLen  \n",
              "0                 255         8        585    4.935312  \n",
              "1                 255         8        585    4.935312  \n",
              "2                 255         8        585    4.935312  \n",
              "3                 255         8        585    4.935312  \n",
              "4                 255         8        585    4.935312  \n",
              "...               ...       ...        ...         ...  \n",
              "408944            659         2       1409    4.137663  \n",
              "408945            659         2       1409    4.137663  \n",
              "408946            659         2       1409    4.137663  \n",
              "408947            659         2       1409    4.137663  \n",
              "408948            659         2       1409    4.137663  \n",
              "\n",
              "[408949 rows x 7 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.reset_index().drop('index',axis=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPipjDsvaeWPmm+I2AKTUv7",
      "collapsed_sections": [],
      "mount_file_id": "1_TEjG8vJVKTW0yXQp99YYob3Mif_LgsQ",
      "name": "NLPproject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
