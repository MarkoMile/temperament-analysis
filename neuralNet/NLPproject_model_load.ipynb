{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 22:02:12.666971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-08 22:02:12.666989: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/marko/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-08 22:02:14.395266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-08 22:02:14.395296: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-08 22:02:14.395315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marko-pc): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./pickle_files/df_odvojeni_word_vectors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spajanje odvojenih postova\n",
    "\n",
    "df = df.groupby(['type', 'avgWordLen'], sort=False,as_index=False).agg({'posts':' '.join,'upperCount':'first','stopWordCount':'first','urlCount':'first','wordCount':'first','avgWordLen':'first'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nospacy ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 1703\n",
    "max_features = 2000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(df['posts'].array)\n",
    "word_index= tokenizer.word_index\n",
    "vectorList = tokenizer.texts_to_sequences(list(df['posts']))\n",
    "vectorList = tf.keras.utils.pad_sequences(vectorList, padding=pad_type, truncating=trunc_type, maxlen=sequence_length,dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spacy ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #padding vektora\n",
    "# def paddingEmbedded(a):\n",
    "#   b = np.zeros([len(a), len(max(a, key=lambda x: len(x))), 300])\n",
    "#   for i, j in enumerate(a):\n",
    "#     if (len(j) == 0):\n",
    "#       continue\n",
    "#     b[i][0:len(j)] = j\n",
    "#     b[i][len(j):] = np.zeros(300,)\n",
    "#   return b\n",
    "\n",
    "\n",
    "# df['vectors'] = df['vectors'].apply(\n",
    "#     lambda x: np.array(list(filter(lambda y: y.ndim > 1, x))))\n",
    "# df = df[df.vectors.map(lambda d: len(d)) >\n",
    "#         0].reset_index().drop('index', axis=1)\n",
    "# df['vectors'] = df['vectors'].apply(lambda x: np.array(\n",
    "#     list(map(lambda y: y.reshape(300,), np.concatenate(x)))))\n",
    "# vectorList = paddingEmbedded(df['vectors'].array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 0.8\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "for ind in df.index:\n",
    "    sentences.append(vectorList[ind])\n",
    "    labels.append(df['type'][ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_sentences, testing_sentences, training_labels, testing_labels = train_test_split(sentences, labels, test_size=1-training_size, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this block to get it to work with TensorFlow 2.x\n",
    "import numpy as np\n",
    "training_labels = np.array(training_labels)\n",
    "testing_labels = np.array(testing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "training_labels = encoder.fit_transform(training_labels.reshape(-1,1)).toarray()\n",
    "testing_labels = encoder.fit_transform(testing_labels.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sentences = np.array(list(testing_sentences))\n",
    "training_sentences = np.array(list(training_sentences))\n",
    "# testing_sentences = tf.convert_to_tensor(testing_sentences)\n",
    "# training_sentences = tf.convert_to_tensor(training_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEpoch = 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 22:02:27.085407: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('saved_models/fullSet_nospacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 6s 104ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(testing_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.58      0.50        90\n",
      "           1       0.63      0.42      0.50       149\n",
      "           2       0.76      0.88      0.82       834\n",
      "           3       0.83      0.70      0.76       662\n",
      "\n",
      "    accuracy                           0.75      1735\n",
      "   macro avg       0.66      0.64      0.64      1735\n",
      "weighted avg       0.76      0.75      0.75      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "pred_max = np.argmax(predict,axis=1)\n",
    "test_max = np.argmax(testing_labels,axis=1)\n",
    "\n",
    "print(skm.classification_report(test_max,pred_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107,  55, 272, ...,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
